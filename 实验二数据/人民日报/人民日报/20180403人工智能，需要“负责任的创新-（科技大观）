
　　想象一下，未来某个人能够通过人工智能软件存在的漏洞，轻松地将无人机改造成具攻击性的半自动战机；一群黑客通过渗透医院的智能医疗设备，敲诈勒索当地政府……随着人工智能技术的快速发展，这个未来可能并不遥远。显然，如果不能防止人工智能技术的恶意使用，社会稳定将遭受威胁。　　过去一年，我们和其他20多位人工智能领域专家，通过思考当前的人工智能技术以及其可能如何被坏人利用，写成了一份报告——《人工智能的恶意使用：预测、防止与缓解》。　　这份报告基于人工智能可能被恶意使用的实际场景，如利用机器人进行非法活动，借助新一代的难以被监测的恶意软件，进行复杂的黑客活动，以及把广告行业的工具功能进一步延展，针对个人精准投放等。事实上，在我们召开研讨会到完成报告的这段时间，随着技术的快速进步，一些听起来像来自科幻小说的假设场景，已经成真。例如，报告有一节讨论了如何使用新的人工智能技术，创建合成视频和音频，炮制知名政客的“假新闻”。这说明，即使了解人工智能技术并为其可能造成的特定威胁做好应对，杜绝这类恶意使用的难度依然不小。　　这份报告为讨论这些问题迈出了第一步，认为只有政府和研究人员都给予持续关注，才有可能识别、预防和减轻这些威胁。我们提出了四点建议。首先，政策制定者应该与技术研究人员密切合作，了解相关技术和目前的风险。其次，人工智能研究人员应当认真考虑技术这把双刃剑，并承担适当责任。第三，需要进行更多的研究，从面临类似问题的其他领域（如计算机安全）学习解决之道。第四，必须将更多的专家和利益相关者纳入对话。　　中国在这些方面有机会发挥主导作用。中国政府在去年7月印发的《新一代人工智能发展规划》中，呼吁“建成更加完善的人工智能法律法规、伦理规范和政策体系”“加强对人工智能潜在危害与收益的评估”，以确保人工智能的健康发展。《规划》还呼吁“深化在人工智能法律法规、国际规则等方面的国际合作，共同应对全球性挑战”。我们对此深表赞同。　　拥有全球性的态度至关重要，这不仅可以有效应对这些本质上跨国界的问题，还可以确保所采取的措施不会阻碍人工智能整体的持续性发展。在应对恶意使用者时，我们不能牺牲掉开放创新的精神，而应该采取“负责任的创新”态度。　　人工智能可以在医药、交通、能源、教育等诸多领域，为中国和世界带来巨大收益。挑战与机遇并存。要享受人工智能的红利，全球必须更有效地应对挑战。　　（作者分别为美国人工智能研究机构OpenAI战略和传播总监、英国牛津大学人工智能治理项目助理研究员）

