
　　当今时代，人工智能日益深刻地影响着人类生活，帮助人类提高工作效率。其中，设计科学的算法、用好大数据资源、不断提高计算能力是人工智能技术发展的重要支点。然而，技术发展总是与风险相伴，人工智能也可能带来侵犯个人隐私、冲击法律与社会伦理等问题。在充分发挥人工智能作用的同时有效防范其风险，需要运用法治思维和法治方式，加强对算法设计和数据运用的监督管理，推动人工智能行业健康成长，更好为经济社会发展服务。　　对算法设计进行监管。人工智能是人类智慧的延伸，算法设计也不是纯粹的技术问题。所有算法都是为完成特定任务、实现特定目的而设计的，特定任务、特定目的的实现路径往往蕴含着设计者的价值观。而设计者的价值观又会影响其设计的技术方案，这就可能在技术运用中产生所谓的算法歧视。比如，某网络公司推出的广告服务中，男性用户能够比女性用户看到更多高薪招聘广告。即使算法设计者没有给算法植入歧视的意图，但有时仍然会出现某种歧视效果。因此，编制算法应当遵循一定的法律规则和行业规则，以合理控制路径选择，使其符合社会基本伦理规范。　　对算法设计进行监管，可以采用专业监督和社会监督等手段。专业监督就是对算法设计制定具有可操作性的技术和行业规范，让设计者在进行设计之前就受到有效制约。还可以请同行专家进行监督。同行专家比较容易洞悉设计者的理念，能够了解具体的操作程序。通过同行专家的评价和信息披露，可以对设计者设计出来的算法进行比较有效的事后规制。社会监督就是要求设计者将其算法设计的基本情况进行登记或备案，并且这种登记或备案信息可供社会公众查询，形成社会公众评判，从而进行道德和舆论上的制约。通过专业监督和社会监督，可以更好地防范人工智能算法设计偏离社会基本伦理规范。　　对数据运用进行监管。数据的获得和利用方式是法律关注的问题。当用户流连于网络、享受人工智能设备带来的便利时，其个人信息安全可能正面临风险。例如，人们使用智能设备，往往要同意所谓的注册协议、服务协议，这些协议通常会要求用户“自愿”提供个人基本信息。企业在获得用户形式上的授权后，服务过程中涉及的个人数据就会按照约定通过网络传送给企业。比如，可以上传用户的位置、兴趣、需求、使用习惯等信息。获得这些数据的企业，可以据此形成消费者分析报告，针对用户的年龄、居住区域、消费习惯差异等，准确把握用户偏好，进行精准的市场投放。因此，数据运用可以给企业带来巨大利益。　　由于互联网海量存储和快速传播的特点，获取、存储和利用个人信息的主体和环节众多，其中往往存在侵犯用户隐私安全和滥用数据的风险。面对这些风险，法律应当确立相应规范，对企业使用个人信息进行限制，使得对个人信息的保护更为详实、充分。例如，允许智能设备出于便捷服务的需要收集个人信息，但不能要求用户作出概括性授权。企业应以正当的、法定的、特定的目的，在特定范围内收集个人信息，并用于特定用途，而不能随意超越用户对其个人信息收集、使用的授权范围。应禁止企业向用户收集与服务无关的信息。服务提供商违反个人信息保护义务的，应当依法承担法律责任。总之，面对人工智能领域可能出现的风险，我们应认真研究思考并作出法律上的应对，为新技术发展设计好法治框架，让人工智能更好地造福人类。　　（作者单位：首都师范大学政法学院）

